{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Dataset Class with Preloading**\n",
    "class PreloadedDataset(Dataset):\n",
    "    def __init__(self, root_dir, categories, sequence_length=8, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (str): Root directory containing category folders.\n",
    "            categories (list): List of category names (subfolder names).\n",
    "            sequence_length (int): Number of consecutive frames in each sequence.\n",
    "            transform (callable, optional): Transform to apply to each frame.\n",
    "        \"\"\"\n",
    "        self.data = []\n",
    "        self.labels = []\n",
    "        self.sequence_length = sequence_length\n",
    "        self.transform = transform\n",
    "\n",
    "        for label, category in enumerate(categories):\n",
    "            category_path = os.path.join(root_dir, category)\n",
    "            if not os.path.exists(category_path):\n",
    "                print(f\"Category folder does not exist: {category_path}\")\n",
    "                continue\n",
    "\n",
    "            # Load all PNGs into memory\n",
    "            print(f\"Preloading category: {category}\")\n",
    "            frame_files = sorted([f for f in os.listdir(category_path) if f.endswith(\".png\")])\n",
    "            for file in frame_files:\n",
    "                img = Image.open(os.path.join(category_path, file)).convert(\"RGB\")\n",
    "                if self.transform:\n",
    "                    img = self.transform(img)\n",
    "                self.data.append(img)  # Add preprocessed image\n",
    "                self.labels.append(label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Create sequences on-the-fly from preloaded data\n",
    "        start_idx = idx\n",
    "        end_idx = start_idx + self.sequence_length\n",
    "\n",
    "        # Handle edge cases by padding with zeros\n",
    "        if end_idx > len(self.data):\n",
    "            sequence = self.data[start_idx:] + [torch.zeros_like(self.data[0])] * (end_idx - len(self.data))\n",
    "        else:\n",
    "            sequence = self.data[start_idx:end_idx]\n",
    "\n",
    "        # Stack into tensor of shape (C, T, H, W)\n",
    "        sequence = torch.stack(sequence, dim=1)\n",
    "        label = self.labels[idx]\n",
    "        return sequence, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimized3DCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Optimized3DCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm3d(32)\n",
    "        self.pool1 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm3d(64)\n",
    "        self.pool2 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv3d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm3d(128)\n",
    "        self.pool3 = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool3d((1, 1, 1))\n",
    "        self.fc = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.global_pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten for the FC layer\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Prepare Datasets and DataLoaders**\n",
    "categories = [\"Abuse\", \"Arson\", \"Assault\", \"Burglary\", \"Explosion\", \"Fighting\",\n",
    "              \"NormalVideos\", \"RoadAccidents\", \"Robbery\", \"Shooting\", \"Shoplifting\",\n",
    "              \"Stealing\", \"Vandalism\"]\n",
    "\n",
    "train_root = \"Train\"\n",
    "test_root = \"Test\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),  # Slight rotations to avoid distortion\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.Resize((112, 112)),  # Ensure the size is consistent\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading category: Abuse\n",
      "Preloading category: Arson\n",
      "Preloading category: Assault\n",
      "Preloading category: Burglary\n",
      "Preloading category: Explosion\n",
      "Preloading category: Fighting\n",
      "Preloading category: NormalVideos\n",
      "Preloading category: RoadAccidents\n",
      "Preloading category: Robbery\n",
      "Preloading category: Shooting\n",
      "Preloading category: Shoplifting\n",
      "Preloading category: Stealing\n",
      "Preloading category: Vandalism\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dataset = PreloadedDataset(root_dir=train_root, categories=categories, sequence_length=16, transform=transform)\n",
    "#\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)  # Preloading, so no workers\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preloading category: Abuse\n",
      "Preloading category: Arson\n",
      "Preloading category: Assault\n",
      "Preloading category: Burglary\n",
      "Preloading category: Explosion\n",
      "Preloading category: Fighting\n",
      "Preloading category: NormalVideos\n",
      "Preloading category: RoadAccidents\n",
      "Preloading category: Robbery\n",
      "Preloading category: Shooting\n",
      "Preloading category: Shoplifting\n",
      "Preloading category: Stealing\n",
      "Preloading category: Vandalism\n"
     ]
    }
   ],
   "source": [
    "test_dataset = PreloadedDataset(root_dir=test_root, categories=categories, sequence_length=8, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\AppData\\Local\\Temp\\ipykernel_20868\\3758203713.py:13: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()  # Mixed precision scaler\n"
     ]
    }
   ],
   "source": [
    "# **Model Setup**\n",
    "num_classes = len(categories)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "model = Optimized3DCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "\n",
    "scaler = GradScaler()  # Mixed precision scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Training Loop**\n",
    "num_epochs = 5\n",
    "save_dir = \"models\"  # Folder to save models\n",
    "os.makedirs(save_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F  # Import this for functional operations\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torch.cuda.amp import GradScaler, autocast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:   0%|          | 0/10648 [00:00<?, ?it/s]C:\\Users\\adars\\AppData\\Local\\Temp\\ipykernel_20868\\1675048004.py:12: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "Epoch 1/5:   0%|          | 0/10648 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Mixed precision training\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast():\n\u001b[1;32m---> 13\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 20\u001b[0m, in \u001b[0;36mOptimized3DCNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 20\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(\u001b[43mF\u001b[49m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x))))\n\u001b[0;32m     21\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))))\n\u001b[0;32m     22\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool3(F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv3(x))))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting Epoch {epoch + 1}/{num_epochs}\")\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(progress_bar):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Mixed precision training\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        # Debug every 10 batches\n",
    "        if batch_idx % 1000 == 0:\n",
    "            print(f\"Batch {batch_idx + 1}/{len(train_loader)}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs} completed with Average Loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    # Save model checkpoint\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f\"simple_3dcnn_epoch_{epoch + 1}.pth\"))\n",
    "    print(f\"Model saved for Epoch {epoch + 1}\")\n",
    "\n",
    "    # Step scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\AppData\\Local\\Temp\\ipykernel_20868\\2143657934.py:14: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: Train Loss = 1.3708, Train Accuracy = 0.6864\n",
      "Starting Epoch 2/5\n",
      "Epoch 2/5: Train Loss = 0.9059, Train Accuracy = 0.8947\n",
      "Starting Epoch 3/5\n",
      "Epoch 3/5: Train Loss = 0.7595, Train Accuracy = 0.9550\n",
      "Starting Epoch 4/5\n",
      "Epoch 4/5: Train Loss = 0.6905, Train Accuracy = 0.9795\n",
      "Starting Epoch 5/5\n",
      "Epoch 5/5: Train Loss = 0.6552, Train Accuracy = 0.9894\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Starting Epoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    # Training Phase\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass and loss calculation\n",
    "        with autocast():\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate training accuracy\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Calculate average training loss and accuracy\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = correct / total\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}: Train Loss = {train_loss:.4f}, Train Accuracy = {train_accuracy:.4f}\")\n",
    "\n",
    "    # Save model checkpoint (optional)\n",
    "    torch.save(model.state_dict(), os.path.join(save_dir, f\"simple_3dcnn_epoch_{epoch + 1}.pth\"))\n",
    "\n",
    "    # Step the learning rate scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.3720, Test Accuracy: 0.3271\n"
     ]
    }
   ],
   "source": [
    "# Test Phase\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "# Calculate average test loss and accuracy\n",
    "test_loss /= len(test_loader)\n",
    "test_accuracy = correct / total\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 32.71%\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully and set to evaluation mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\adars\\AppData\\Local\\Temp\\ipykernel_18272\\1257002490.py:21: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  saved_model_path = \"models_with_additional_layers\\simple_3dcnn_epoch_5.pth\"  # Replace with your actual saved file name\n",
      "C:\\Users\\adars\\AppData\\Local\\Temp\\ipykernel_18272\\1257002490.py:24: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(saved_model_path))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define categories and device\n",
    "categories = [\"Abuse\", \"Arson\", \"Assault\", \"Burglary\", \"Explosion\", \"Fighting\",\n",
    "              \"NormalVideos\", \"RoadAccidents\", \"Robbery\", \"Shooting\", \"Shoplifting\",\n",
    "              \"Stealing\", \"Vandalism\"]\n",
    "num_classes = len(categories)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the model\n",
    "model = Optimized3DCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "# Path to the saved model\n",
    "saved_model_path = \"models_with_additional_layers\\simple_3dcnn_epoch_5.pth\"  # Replace with your actual saved file name\n",
    "\n",
    "# Load the saved state dictionary\n",
    "model.load_state_dict(torch.load(saved_model_path))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully and set to evaluation mode.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VIDEO PROCESSING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract frames from a video\n",
    "def extract_frames(video_path, sequence_length=8):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = Image.fromarray(frame)  # Convert frame to PIL Image\n",
    "        frame = transform(frame)       # Apply defined transform\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "\n",
    "    # Split frames into sequences\n",
    "    frame_sequences = []\n",
    "    for i in range(0, len(frames) - sequence_length + 1, sequence_length):\n",
    "        frame_sequences.append(torch.stack(frames[i:i + sequence_length], dim=1))  # Shape: (C, T, H, W)\n",
    "\n",
    "    return frame_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\adars\\AppData\\Local\\Temp\\ipykernel_18272\\2884218857.py:2: SyntaxWarning: invalid escape sequence '\\s'\n",
      "  model.load_state_dict(torch.load(\"models_with_additional_layers\\simple_3dcnn_epoch_5.pth\"))  # Update with your saved model path\n",
      "C:\\Users\\adars\\AppData\\Local\\Temp\\ipykernel_18272\\2884218857.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"models_with_additional_layers\\simple_3dcnn_epoch_5.pth\"))  # Update with your saved model path\n"
     ]
    }
   ],
   "source": [
    "model = Optimized3DCNN(num_classes=13)\n",
    "model.load_state_dict(torch.load(\"models_with_additional_layers\\simple_3dcnn_epoch_5.pth\"))  # Update with your saved model path\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict_video(video_path):\n",
    "    frame_sequences = extract_frames(video_path, sequence_length=16)\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for frame_sequence in frame_sequences:\n",
    "            frame_sequence = frame_sequence.unsqueeze(0).to(device)  # Add batch dimension\n",
    "            outputs = model(frame_sequence)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            predictions.append(predicted.item())\n",
    "    # Return the most common predicted class\n",
    "    return max(set(predictions), key=predictions.count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\R'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\R'\n",
      "C:\\Users\\adars\\AppData\\Local\\Temp\\ipykernel_18272\\3703828210.py:2: SyntaxWarning: invalid escape sequence '\\R'\n",
      "  video_path = \"output_folder_video\\RoadAccidents017_x264.avi\"  # Replace with your video path\n"
     ]
    }
   ],
   "source": [
    "# Run prediction\n",
    "video_path = \"output_folder_video\\RoadAccidents017_x264.avi\"  # Replace with your video path\n",
    "predicted_class = predict_video(video_path)\n",
    "print(f\"Predicted Class: {predicted_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Category: Explosion\n"
     ]
    }
   ],
   "source": [
    "categories = [\"Abuse\", \"Arson\", \"Assault\", \"Burglary\", \"Explosion\", \"Fighting\",\n",
    "              \"NormalVideos\", \"RoadAccidents\", \"Robbery\", \"Shooting\", \"Shoplifting\",\n",
    "              \"Stealing\", \"Vandalism\"]\n",
    "\n",
    "print(f\"Predicted Category: {categories[predicted_class]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
